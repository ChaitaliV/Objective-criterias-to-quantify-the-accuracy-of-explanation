{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 15:43:40.696780: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 15:43:41.094632: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-29 15:43:41.094669: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-29 15:43:42.598561: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-29 15:43:42.599016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-29 15:43:42.599029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from model import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383 Validation Data loaded\n"
     ]
    }
   ],
   "source": [
    "# load all test data\n",
    "x_test,y_test = load_pkl_data(test_pkl)\n",
    "print(\"%d Validation Data loaded\"%(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded\n",
      "Total 3 classes\n"
     ]
    }
   ],
   "source": [
    "# load label maps\n",
    "label2ind = load_dict_from_json(label2ind_json)\n",
    "ind2label = load_dict_from_json(ind2label_json)\n",
    "print(\"Labels loaded\")\n",
    "nc = len(label2ind.keys())\n",
    "print(\"Total %d classes\"%nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 15:43:50.654197: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 15:43:50.654762: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-29 15:43:50.654928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-29 15:43:50.655004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-29 15:43:50.680917: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-29 15:43:50.680987: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-29 15:43:50.681031: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-29 15:43:50.681043: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-29 15:43:50.681731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'bert.embeddings.position_ids', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n"
     ]
    }
   ],
   "source": [
    "model = AttentionClassifier(nc)\n",
    "print(\"Model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model restored weights from None\n"
     ]
    }
   ],
   "source": [
    "model.load_model(\"model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Index 99\n",
      "पत्त्नी तो किसी की भी पत्त्नी हो उसका हसबैंड ड्रिंक english husband drink क्र रहा है तो उसको कुछ ना कुछ बोलेंगी ही।\n",
      "Label: dd\n"
     ]
    }
   ],
   "source": [
    "# take a random data from test\n",
    "n_test = len(x_test)\n",
    "rand_idx = np.random.randint(0,n_test)\n",
    "print(\"Random Index %d\"%rand_idx)\n",
    "test_text = x_test[rand_idx]\n",
    "test_label = y_test[rand_idx]\n",
    "print(test_text)\n",
    "print(\"Label: %s\"%test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intro\n",
      "Predicted label: intro\n",
      "\n",
      "Word level attention\n",
      "\n",
      "[CLS] 0.027782097458839417\n",
      "पत्त्नी 0.08328153192996979\n",
      "तो 0.027782145887613297\n",
      "किसी 0.02776734158396721\n",
      "की 0.027743935585021973\n",
      "भी 0.027789050713181496\n",
      "पत्त्नी 0.08325383067131042\n",
      "हो 0.02774673141539097\n",
      "उसका 0.027796071022748947\n",
      "हसबैंड 0.11115034855902195\n",
      "ड्रिंक 0.08332918584346771\n",
      "english 0.02774883806705475\n",
      "husband 0.027820425108075142\n",
      "drink 0.027784837409853935\n",
      "क्र 0.02778949774801731\n",
      "रहा 0.027738595381379128\n",
      "है 0.0277777798473835\n",
      "तो 0.027798287570476532\n",
      "उसको 0.0277823768556118\n",
      "कुछ 0.027794718742370605\n",
      "ना 0.02781176008284092\n",
      "कुछ 0.02778775990009308\n",
      "बोलेंगी 0.05555106699466705\n",
      "ही 0.027821529656648636\n",
      "। 0.027788175269961357\n",
      "[SEP] 0.027782097458839417\n"
     ]
    }
   ],
   "source": [
    "word_attention,label = model.predict_with_explain(test_text,ind2label)\n",
    "print(\"Predicted label: %s\"%label)\n",
    "print()\n",
    "print(\"Word level attention\")\n",
    "print()\n",
    "for w in word_attention:\n",
    "    print(w[0],w[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2361 (\\N{DEVANAGARI LETTER HA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Matplotlib currently does not support Devanagari natively.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2366 (\\N{DEVANAGARI VOWEL SIGN AA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2305 (\\N{DEVANAGARI SIGN CANDRABINDU}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2313 (\\N{DEVANAGARI LETTER U}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2344 (\\N{DEVANAGARI LETTER NA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2381 (\\N{DEVANAGARI SIGN VIRAMA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2379 (\\N{DEVANAGARI VOWEL SIGN O}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2306 (\\N{DEVANAGARI SIGN ANUSVARA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2375 (\\N{DEVANAGARI VOWEL SIGN E}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2347 (\\N{DEVANAGARI LETTER PHA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2364 (\\N{DEVANAGARI SIGN NUKTA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2325 (\\N{DEVANAGARI LETTER KA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2367 (\\N{DEVANAGARI VOWEL SIGN I}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2351 (\\N{DEVANAGARI LETTER YA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2327 (\\N{DEVANAGARI LETTER GA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2350 (\\N{DEVANAGARI LETTER MA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2340 (\\N{DEVANAGARI LETTER TA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2354 (\\N{DEVANAGARI LETTER LA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2348 (\\N{DEVANAGARI LETTER BA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2369 (\\N{DEVANAGARI VOWEL SIGN U}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2333 (\\N{DEVANAGARI LETTER JHA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2368 (\\N{DEVANAGARI VOWEL SIGN II}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2346 (\\N{DEVANAGARI LETTER PA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2311 (\\N{DEVANAGARI LETTER I}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2360 (\\N{DEVANAGARI LETTER SA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2357 (\\N{DEVANAGARI LETTER VA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2352 (\\N{DEVANAGARI LETTER RA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2326 (\\N{DEVANAGARI LETTER KHA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2341 (\\N{DEVANAGARI LETTER THA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2332 (\\N{DEVANAGARI LETTER JA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/home/ashish/.local/lib/python3.8/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 2404 (\\N{DEVANAGARI DANDA}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "words = []\n",
    "for w,a in word_attention:\n",
    "    scores.append(a)\n",
    "    words.append(w)\n",
    "# scores = np.log(scores)\n",
    "plt.imshow(np.expand_dims(scores,1),cmap='hot')\n",
    "plt.yticks(range(len(words)),words,rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Squeeze_device_/job:localhost/replica:0/task:0/device:CPU:0}} Can not squeeze dim[0], expected a dimension of 1, got 10 [Op:Squeeze]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m decoded \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mencoder_layer\u001b[39m.\u001b[39mpreprocess_layer\u001b[39m.\u001b[39mdecode(tf\u001b[39m.\u001b[39;49msqueeze(words,\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)) \n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(decoded)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Squeeze_device_/job:localhost/replica:0/task:0/device:CPU:0}} Can not squeeze dim[0], expected a dimension of 1, got 10 [Op:Squeeze]"
     ]
    }
   ],
   "source": [
    "decoded = model.encoder_layer.preprocess_layer.decode(tf.squeeze(words,-1)) \n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] ['[CLS]']\n",
      "[1, 2] ['angel', '##is']\n",
      "[3] ['yep']\n",
      "[4] ['which']\n",
      "[5] ['is']\n",
      "[6, 7] ['mess', '##ier']\n",
      "[8] ['more']\n",
      "[9] ['dangerous']\n",
      "[10] ['more']\n",
      "[11] ['environmentally']\n",
      "[12, 13, 14, 15] ['un', '##fr', '##ien', '##dly']\n",
      "[16] ['than']\n",
      "[17] ['their']\n",
      "[18, 19, 20] ['re', '##tar', '##ded']\n",
      "[21] ['new']\n",
      "[22, 23] ['sp', '##outs']\n",
      "[24] ['[SEP]']\n"
     ]
    }
   ],
   "source": [
    "sub_word_ids = model.encoder_layer.preprocess_layer.encode(test_tweet)\n",
    "sub_word_dict = {}\n",
    "for i,sw in enumerate(sub_word_ids):\n",
    "    sub_word_dict[i] = sw\n",
    "# print(sub_word_dict)\n",
    "word_spans = []\n",
    "subword_list = []\n",
    "for k in sub_word_dict.keys():\n",
    "    sid = sub_word_dict[k]\n",
    "    sub_word = model.encoder_layer.preprocess_layer.convert_ids_to_tokens(sid)\n",
    "    if \"##\" in sub_word:\n",
    "        word_spans[-1].append(k)\n",
    "        subword_list[-1].append(sub_word)\n",
    "    else:\n",
    "        word_spans.append([k])\n",
    "        subword_list.append([sub_word])\n",
    "    # print(k,sid,sub_word)\n",
    "for i,s in zip(word_spans,subword_list):\n",
    "    print(i,s)\n",
    "# all_spans = []\n",
    "# for id_ in word_ids:\n",
    "#     sub_word = model.encoder_layer.preprocess_layer.convert_ids_to_tokens(id_)\n",
    "#     if \"##\" in sub_word:\n",
    "#         all_spans[-1].append(id_)\n",
    "#     else:\n",
    "#         all_spans.append([id_])\n",
    "#     # print(id_,sub_word)\n",
    "# word_span = {}\n",
    "# for i,sp in enumerate(all_spans):\n",
    "#     sub_list = []\n",
    "#     sub_idx = []\n",
    "#     for s in sp:\n",
    "#         sub_word = model.encoder_layer.preprocess_layer.convert_ids_to_tokens(s)\n",
    "#         sub_list.append(sub_word.replace(\"##\",\"\"))\n",
    "#         sub_idx.append(s)\n",
    "#     wd = ''.join(sub_list)\n",
    "#     word_span[str(i)] = {\"word\":wd,\"subword_index\":sub_idx}\n",
    "# print(word_span)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tatras_p310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

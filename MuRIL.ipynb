{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Th2l5qK38u7G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675340728511,"user_tz":-330,"elapsed":24703,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"}},"outputId":"b4974ddf-3f74-4473-b838-52a5a815598e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"TZCatW_y80Gm","executionInfo":{"status":"ok","timestamp":1675340733643,"user_tz":-330,"elapsed":1064,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"}}},"outputs":[],"source":["from IPython.display import Image"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12047,"status":"ok","timestamp":1675340752849,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"yNi96akH9F-9","outputId":"c2a7776a-d708-4c7c-9925-4c7278981ae2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-pretrained-bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytorch-nlp\n","  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (2.25.1)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (1.13.1+cu116)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (1.21.6)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (2022.6.2)\n","Collecting boto3\n","  Downloading boto3-1.26.62-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from pytorch-pretrained-bert) (4.64.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.4.0)\n","Collecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.7.0,>=0.6.0\n","  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore<1.30.0,>=1.29.62\n","  Downloading botocore-1.29.62-py3-none-any.whl (10.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.62->boto3->pytorch-pretrained-bert) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.62->boto3->pytorch-pretrained-bert) (1.15.0)\n","Installing collected packages: urllib3, pytorch-nlp, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed boto3-1.26.62 botocore-1.29.62 jmespath-1.0.1 pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.6.0 urllib3-1.26.14\n"]}],"source":["!pip install pytorch-pretrained-bert pytorch-nlp"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12132,"status":"ok","timestamp":1675340768166,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"t63QvFPE9G7s","outputId":"28c0a8ba-f12d-4ca1-f66c-413fd7ee204c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q transformers"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"mMVwcXzR9KMl","executionInfo":{"status":"ok","timestamp":1675340779779,"user_tz":-330,"elapsed":6202,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras_preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, BertConfig\n","from transformers import AdamW, BertForSequenceClassification, get_linear_schedule_with_warmup\n","from tqdm import tqdm, trange\n","import pandas as pd\n","import io\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1675340783685,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"wQU1AKdv9OdC","outputId":"d489532f-1141-44a8-a691-aecbe39f405d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":6}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":1392,"status":"ok","timestamp":1675340787686,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"P1zLJQXn9h6D","outputId":"e377c4f2-0519-4c7b-afc9-04976e5a3258"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                                               text task_1\n","0           0                  वक्त इन्सान इंग्लैंड मौसम धोखा दे    NOT\n","1           1  कांग्रेस कमीने करतूत देखिए देश रक्षा शहीद मां ...    HOF\n","2           2  पाकिस्तान फेकना फेका गया। हार दुश्मन हरा दे ना...    HOF\n","3           3  शब्द तूम औरत यूज बचाकर रखना क्योंकि तुम्हारी म...    NOT\n","4           4  नेता समाजवादी सिपाही हमेशा आपके हर निर्णय हमे ...    NOT"],"text/html":["\n","  <div id=\"df-ad7dff64-c815-4f06-954b-b7399ffc0a66\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>task_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>वक्त इन्सान इंग्लैंड मौसम धोखा दे</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>कांग्रेस कमीने करतूत देखिए देश रक्षा शहीद मां ...</td>\n","      <td>HOF</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>पाकिस्तान फेकना फेका गया। हार दुश्मन हरा दे ना...</td>\n","      <td>HOF</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>शब्द तूम औरत यूज बचाकर रखना क्योंकि तुम्हारी म...</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>नेता समाजवादी सिपाही हमेशा आपके हर निर्णय हमे ...</td>\n","      <td>NOT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad7dff64-c815-4f06-954b-b7399ffc0a66')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ad7dff64-c815-4f06-954b-b7399ffc0a66 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ad7dff64-c815-4f06-954b-b7399ffc0a66');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}],"source":["df = pd.read_csv('/content/drive/MyDrive/HASOC_cleaned_data.csv')\n","df.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":615,"status":"ok","timestamp":1675340790540,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"0W4Z89l19wf9","outputId":"7b6ba0dd-304e-4b83-e58d-4818f1fb0e01"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          hindi_text label\n","0                  वक्त इन्सान इंग्लैंड मौसम धोखा दे   NOT\n","1  कांग्रेस कमीने करतूत देखिए देश रक्षा शहीद मां ...   HOF\n","2  पाकिस्तान फेकना फेका गया। हार दुश्मन हरा दे ना...   HOF\n","3  शब्द तूम औरत यूज बचाकर रखना क्योंकि तुम्हारी म...   NOT\n","4  नेता समाजवादी सिपाही हमेशा आपके हर निर्णय हमे ...   NOT"],"text/html":["\n","  <div id=\"df-35c7ec32-93ad-40a5-bd60-52d1809e8120\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hindi_text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>वक्त इन्सान इंग्लैंड मौसम धोखा दे</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>कांग्रेस कमीने करतूत देखिए देश रक्षा शहीद मां ...</td>\n","      <td>HOF</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>पाकिस्तान फेकना फेका गया। हार दुश्मन हरा दे ना...</td>\n","      <td>HOF</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>शब्द तूम औरत यूज बचाकर रखना क्योंकि तुम्हारी म...</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>नेता समाजवादी सिपाही हमेशा आपके हर निर्णय हमे ...</td>\n","      <td>NOT</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35c7ec32-93ad-40a5-bd60-52d1809e8120')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-35c7ec32-93ad-40a5-bd60-52d1809e8120 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-35c7ec32-93ad-40a5-bd60-52d1809e8120');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":8}],"source":["df.drop('Unnamed: 0', axis=1, inplace=True)\n","df.rename(columns = {'text':'hindi_text', 'task_1' :'label'}, inplace = True)\n","df.head()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1675340792996,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"v-jY63M0-9Re","outputId":"84b371a9-b061-41fd-d8ab-f2ac00cf4f94"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9077, 2)"]},"metadata":{},"execution_count":9}],"source":["df = df[df['label'].notna()]\n","df.shape"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"fSU7hMTRuIg0","executionInfo":{"status":"ok","timestamp":1675340795613,"user_tz":-330,"elapsed":8,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"}}},"outputs":[],"source":["df['label'] = pd.Categorical(df['label'])                             ## labels are changed such that\n","df['label'] = df['label'].cat.rename_categories([0, 1])               ## NOT : 1, HOF : 0"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1675340796794,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"kFJ3kHiruOkV","outputId":"061a719e-cd91-4ce9-fa7f-0b57815f7274"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                             hindi_text label\n","0                     वक्त इन्सान इंग्लैंड मौसम धोखा दे     1\n","1     कांग्रेस कमीने करतूत देखिए देश रक्षा शहीद मां ...     0\n","2     पाकिस्तान फेकना फेका गया। हार दुश्मन हरा दे ना...     0\n","3     शब्द तूम औरत यूज बचाकर रखना क्योंकि तुम्हारी म...     1\n","4     नेता समाजवादी सिपाही हमेशा आपके हर निर्णय हमे ...     1\n","...                                                 ...   ...\n","9072  पाकिस्तान हिंदुओं ख़िलाफ़ बोलने बर्खास्त भारत ...     1\n","9073  कोहली नेहरू नहीं अंग्रेजों तलवे चाटने लगे भड़व...     0\n","9074                        परशुराम जिसने मां हत्या थीं     1\n","9075  देश कन्हैया कुमार पढ़ा लिखा युवा हार जाए आतंकव...     0\n","9076  बापों दम नहीं भारत इस्लामिक स्टेट बना सकें भार...     0\n","\n","[9077 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-b3353f4d-d075-48b2-a987-06247bc5b136\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hindi_text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>वक्त इन्सान इंग्लैंड मौसम धोखा दे</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>कांग्रेस कमीने करतूत देखिए देश रक्षा शहीद मां ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>पाकिस्तान फेकना फेका गया। हार दुश्मन हरा दे ना...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>शब्द तूम औरत यूज बचाकर रखना क्योंकि तुम्हारी म...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>नेता समाजवादी सिपाही हमेशा आपके हर निर्णय हमे ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9072</th>\n","      <td>पाकिस्तान हिंदुओं ख़िलाफ़ बोलने बर्खास्त भारत ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9073</th>\n","      <td>कोहली नेहरू नहीं अंग्रेजों तलवे चाटने लगे भड़व...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9074</th>\n","      <td>परशुराम जिसने मां हत्या थीं</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9075</th>\n","      <td>देश कन्हैया कुमार पढ़ा लिखा युवा हार जाए आतंकव...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9076</th>\n","      <td>बापों दम नहीं भारत इस्लामिक स्टेट बना सकें भार...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9077 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3353f4d-d075-48b2-a987-06247bc5b136')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b3353f4d-d075-48b2-a987-06247bc5b136 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b3353f4d-d075-48b2-a987-06247bc5b136');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["df"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"QwdvQYC6-7YT","executionInfo":{"status":"ok","timestamp":1675340798167,"user_tz":-330,"elapsed":3,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"}}},"outputs":[],"source":["# Creating sentence, label lists and adding Bert tokens\n","sentences = df.hindi_text.values\n","\n","# Adding CLS and SEP tokens at the beginning and end of each sentence for BERT\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","labels = df.label.values"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":197,"referenced_widgets":["9588b5813ef5456aa57b7924fcea30a2","b40a084bacfd4958920ae9976d450481","1afd48a2ae2741eca677e09b7e594849","700c5f4355444766aaa229cf60bd1244","71215226a4414985bc165bad46ff32ed","6910125828ea451ea922f7be1f6c0577","7f8650108e1e468da2fa5cd26243f07a","4ca800bb00e548eaaf553a8732f40936","6256935e983a42d28787c18ecd22f6f0","f02327d3b21b4a68b3d920fabb2a3bee","9a549e69425740ea9f1c74819a400835","4cf6c7d8a6604f599acd9d82c3f7e61e","3c8c4c8cbf9647d0b25033186427337b","35f8e944ab0447778cb8e66c7df37929","97d3818d2f6d4342971747d8e8516c55","743d5826bda94e9bb3e95907720cff9c","28a02a41b1e5464aa685137c787f4c6d","e908c8dbe4604eb097c5530c4dba012d","6d4863c9e7ab479c9f8137690d8cd9b6","6803d68c549d419682023aadbd8e8ff5","c2f62f1da60d44309820e6082ceb9afc","3fd7b2cb65b3450783dadf406c3780b4","272849c61db64f9f936662115753b3ea","34cbe33922334c0db3f1852c8a6c689d","8e0facfc3e5a44f68ab10f75aa230895","a58b1bfbc6364adebec0adb04c03b68c","ec6c57c84dba448a94b78eced1b39428","ef3aebf344a7477a921069370c631ee0","47f5bb58546c4ff7b1e7e60350ce99e4","e3f35d9d72fd40abb6d7d9b1edcf249f","b0035e4f59574996be1cab12acf72325","56de27321ef14c4e98873bf2d1fa9869","21959b3bf2064377aca7bfe52029a35b","889fbcb3cffb4daba84cf1e3c24f157a","60bb048ca3da42e6bd58b2a7d83a710f","39a51dbbfa034d68bf593eb604407a7f","cb714e75828e4d5abd2c095affd44017","4a0348b253a14c98a4631c1fa3ab7b14","c1189a1b790842229a9f5f4b0c232c58","f50d2fd6f14146a6be4f97203ba86e5f","676b3b277c064d95821f59484f858724","5a8585ba9b8040b489e67a6c484b504e","3b6ce6c2e08f499c996b7cfd618d33d9","8309d4c04c394fb9a6278066767ed182"]},"executionInfo":{"elapsed":12776,"status":"ok","timestamp":1675340812381,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"YHH1nE5-_gkk","outputId":"9138c6f0-ae56-45c0-c891-46fda5e171dd"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9588b5813ef5456aa57b7924fcea30a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/113 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cf6c7d8a6604f599acd9d82c3f7e61e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"272849c61db64f9f936662115753b3ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"889fbcb3cffb4daba84cf1e3c24f157a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Tokenize the first sentence:\n","['[CLS]', 'वक्त', 'इन्सान', 'इंग्लैंड', 'मौसम', 'धोखा', 'दे', '[SEP]']\n","8\n"]}],"source":["#@title Activating the BERT Tokenizer\n","tokenizer = BertTokenizer.from_pretrained('google/muril-base-cased')\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","print (\"Tokenize the first sentence:\")\n","print(tokenized_texts[0])\n","print (len(tokenized_texts[0]))"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1675340812382,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"Hw5dUQl4_xYk","outputId":"b4b2a073-93f1-4564-943b-7c1e3fcad031"},"outputs":[{"output_type":"stream","name":"stdout","text":["8\n","128\n"]}],"source":["#Processing the data\n","# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n","# In the original paper, the authors used a length of 512.\n","MAX_LEN = 128\n","\n","# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","print(len(input_ids[0]))\n","# Pad our input tokens\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","print(len(input_ids[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":928,"status":"ok","timestamp":1675083182772,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"M8ZMTQRt_0iA","outputId":"e7c6742f-6bab-438a-dd01-879dd85f0b5c"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'numpy.ndarray'>\n","8577\n","500\n","8577\n"]}],"source":["#Create attention masks\n","attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)\n","\n","print(type(input_ids))\n","train_ids = input_ids[0:-500]\n","train_label = labels[0:-500]\n","test_ids = input_ids[-500:]\n","test_label = labels[-500:]\n","train_attention_masks = attention_masks[0:-500]\n","test_attention_masks = attention_masks[-500:]\n","print(len(train_label))\n","print(len(test_attention_masks))\n","print(len(train_ids))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZ0yKPK6_4Ck"},"outputs":[],"source":["# Splitting data into train and validation sets\n","# Use train_test_split to split our data into train and validation sets for training\n","\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_ids, train_label,random_state = 2018, test_size = 0.1 )\n","train_masks, validation_masks, _, _ = train_test_split(train_attention_masks, train_ids,\n","                                             random_state=2018, test_size=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1675083186340,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"fgYNnmJ0_6s9","outputId":"adcda42b-abc1-4dba-8981-685e402fdaed"},"outputs":[{"data":{"text/plain":["list"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["type(validation_masks)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":437,"status":"ok","timestamp":1675083196762,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"aaK7XGEH_9wM","outputId":"b5b896e0-d249-46cb-f0d1-1bfa2efc691c"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'torch.Tensor'>\n"]}],"source":["#Converting all the data into torch tensors\n","# Torch tensors are the required datatype for our model\n","\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)\n","print(type(train_inputs))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1675083201413,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"bO4Wek2gAAtT","outputId":"67826d59-8757-4245-b47a-a91c1c3fa777"},"outputs":[{"name":"stdout","output_type":"stream","text":["7719\n"]}],"source":["# Selecting a Batch Size and Creating and Iterator\n","# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n","batch_size = 16\n","\n","# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n","# with an iterator the entire dataset does not need to be loaded into memory\n","print(len(train_inputs))\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1361,"status":"ok","timestamp":1675083206718,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"436F6j3cADUQ","outputId":"a79e1e90-33da-4bf3-a796-a7bb7ef33524"},"outputs":[{"name":"stdout","output_type":"stream","text":["BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.26.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n"]}],"source":["# Bert Model Configuration\n","# Initializing a BERT bert-base-uncased style configuration\n","# Transformer Installation\n","try:\n","  import transformers\n","except:\n","  print(\"Installing transformers\")\n","  !pip -qq install transformers\n","  \n","from transformers import BertModel, BertConfig\n","configuration = BertConfig()\n","\n","# Initializing a model from the bert-base-uncased style configuration\n","# This process will load only configuration and not the weights associated with the model\n","model = BertModel(configuration)\n","\n","# Accessing the model configuration\n","configuration = model.config\n","print(configuration)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["7181fe376c3f41b6a2366a31d2a6dcb3","96dca1e278734dbf9c2889b8d0dd6cc2","9b72d04191bd44ab9f64c8eb7819a581","3e5f4a6494e3410b9e37e034d9f7ef11","6170f638a1ab458cb23e540a8a003995","bea265908ebe45b4b88806ecad1f722f","b6757b87f2524f91ad554c76e0668d4e","cecc940a23794fa8b233dbf101786758","14cd2cddf5a34cd4804dfeee0fcd038c","fe0f8b5bc57f475fb2476975ec50904e","6b713841b07a4b0a8a3021bda0a325f7"]},"executionInfo":{"elapsed":13954,"status":"ok","timestamp":1675083245885,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"80xqTI02AH2R","outputId":"b4fabb9f-5a59-4972-8a64-c9a08d745927"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7181fe376c3f41b6a2366a31d2a6dcb3","version_major":2,"version_minor":0},"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/953M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at google/muril-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["DataParallel(\n","  (module): BertForSequenceClassification(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(197285, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=768, out_features=3, bias=True)\n","  )\n",")"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["# Loading the Hugging Face Bert Uncased Base Model \n","model = BertForSequenceClassification.from_pretrained(\"google/muril-base-cased\", num_labels=3)\n","model = nn.DataParallel(model)\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7V-IBfyAPZz"},"outputs":[],"source":["# Optimizer Grouped Parameters\n","# reference:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L102\n","\n","# Don't apply weight decay to any parameters whose names include these tokens.\n","# (Here, the BERT doesn't have `gamma` or `beta` parameters, only `bias` terms)\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.weight']\n","# Separate the `weight` parameters from the `bias` parameters. \n","# - For the `weight` parameters, this specifies a 'weight_decay_rate' of 0.01. \n","# - For the `bias` parameters, the 'weight_decay_rate' is 0.0. \n","optimizer_grouped_parameters = [\n","    # Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.1},\n","    \n","    # Filter for parameters which *do* include those.\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","# Note - `optimizer_grouped_parameters` only includes the parameter values, not \n","# the names."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gp5_UoycAWsT"},"outputs":[],"source":["# The Hyperparameters for the Training Loop \n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 3\n","\n","optimizer = AdamW(optimizer_grouped_parameters,\n","                  lr = 3e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                  )\n","# Total number of training steps is number of batches * number of epochs.\n","# `train_dataloader` contains batched data so `len(train_dataloader)` gives \n","# us the number of batches.\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0.1, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VNotcJFeAX4G"},"outputs":[],"source":["#Creating the Accuracy Measurement Function\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":576067,"status":"ok","timestamp":1675084884917,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"Z2K69K3iAase","outputId":"2921b643-2755-4c94-e68a-6a638697ab75"},"outputs":[{"name":"stderr","output_type":"stream","text":["\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Train loss: 0.13986596337849308\n"]},{"name":"stderr","output_type":"stream","text":["\rEpoch:  33%|███▎      | 1/3 [03:11<06:23, 191.92s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation Accuracy: 0.8013888888888888\n","Train loss: 0.10216861037348492\n"]},{"name":"stderr","output_type":"stream","text":["\rEpoch:  67%|██████▋   | 2/3 [06:23<03:11, 191.68s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation Accuracy: 0.8076388888888888\n","Train loss: 0.08336793304677459\n"]},{"name":"stderr","output_type":"stream","text":["Epoch: 100%|██████████| 3/3 [09:35<00:00, 191.72s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation Accuracy: 0.8064814814814815\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# The Training Loop\n","t = [] \n","\n","# Store our loss and accuracy for plotting\n","train_loss_set = []\n","\n","# trange is a tqdm wrapper around the normal python range\n","for _ in trange(epochs, desc=\"Epoch\"):\n","  \n","  \n","  # Training\n","  \n","  # Set our model to training mode (as opposed to evaluation mode)\n","  model.train()\n","  \n","  # Tracking variables\n","  tr_loss = 0\n","  nb_tr_examples, nb_tr_steps = 0, 0\n","  \n","  # Train the data for one epoch\n","  for step, batch in enumerate(train_dataloader):\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    # Clear out the gradients (by default they accumulate)\n","    optimizer.zero_grad()\n","    # Forward pass\n","    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","    loss = outputs['loss']\n","    train_loss_set.append(loss.item())    \n","    # Backward pass\n","    loss.backward()\n","    # Update parameters and take a step using the computed gradient\n","    optimizer.step()\n","\n","    # Update the learning rate.\n","    scheduler.step()\n","    \n","    \n","    # Update tracking variables\n","    tr_loss += loss.item()\n","    nb_tr_examples += b_input_ids.size(0)\n","    nb_tr_steps += 1\n","\n","  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","    \n","    \n","  # Validation\n","\n","  # Put model in evaluation mode to evaluate loss on the validation set\n","  model.eval()\n","\n","  # Tracking variables \n","  eval_loss, eval_accuracy = 0, 0\n","  nb_eval_steps, nb_eval_examples = 0, 0\n","\n","  # Evaluate data for one epoch\n","  for batch in validation_dataloader:\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","    with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    \n","    # Move logits and labels to CPU\n","    logits = logits['logits'].detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    \n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":417,"status":"ok","timestamp":1675084897654,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"VQect4RLAgxy","outputId":"8fb07a8d-dfd9-4eac-c94c-9a51279ebe43"},"outputs":[{"name":"stdout","output_type":"stream","text":["500\n","500\n","500\n"]}],"source":["prediction_inputs = torch.tensor(test_ids)\n","prediction_masks = torch.tensor(test_attention_masks)\n","prediction_labels = torch.tensor(test_label)\n","  \n","batch_size = 32  \n","print(len(test_ids))\n","print(len(test_attention_masks))\n","print(len(test_label))\n","\n","prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"widWgv74Aopl"},"outputs":[],"source":["# Prediction on test set\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n","  with torch.no_grad():\n","    # Forward pass, calculate logit predictions\n","    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","  # Move logits and labels to CPU\n","  logits = logits['logits'].detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U6W7TA2yAr6r"},"outputs":[],"source":["torch.save(model,r'/content/drive/MyDrive/MuRIL_HASOC.pt')"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"ZjzYhG63145C","executionInfo":{"status":"ok","timestamp":1675340851292,"user_tz":-330,"elapsed":15272,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"}}},"outputs":[],"source":["model=torch.load(r'/content/drive/MyDrive/MuRIL_HASOC.pt',map_location=torch.device('cuda'))"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":2430,"status":"ok","timestamp":1675340857552,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"uwYmGKMG76Va","outputId":"65c9c783-b2c5-47e5-c9e3-b36fef974765"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0  0                           1  \\\n","0           0  0  AI_170_result_slice_140000   \n","1           1  1                         NaN   \n","2           2  2                         NaN   \n","3           3  3                         NaN   \n","4           4  4   AI_170_result_slice_70000   \n","\n","                                                   2  \\\n","0  I run the machine for the jeans etc., which ar...   \n","1  Apart from this, sir, after doing normal work ...   \n","2  Sir, income is work in contract, Sir what happ...   \n","3  Almost in a month - there is work according to...   \n","4                                   my name is Sonu.   \n","\n","                                                   3    4  \n","0  जो जीन्स वगैरा बनती है ना जो इनकी लुपियाँ होती...  0.0  \n","1  इसके आलावा सर ( english : sir ) तो में नार्मल ...  0.0  \n","2  सर ( english : sir ) आमदनी ठेके में काम है सर ...  0.0  \n","3  एक महीने में लगभग - लगभग ठेके के हिसाब का काम ...  0.0  \n","4                                  मेरा नाम सोनू है।  0.0  "],"text/html":["\n","  <div id=\"df-f07849be-b834-45b2-b07e-082ab97975c1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>AI_170_result_slice_140000</td>\n","      <td>I run the machine for the jeans etc., which ar...</td>\n","      <td>जो जीन्स वगैरा बनती है ना जो इनकी लुपियाँ होती...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Apart from this, sir, after doing normal work ...</td>\n","      <td>इसके आलावा सर ( english : sir ) तो में नार्मल ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>Sir, income is work in contract, Sir what happ...</td>\n","      <td>सर ( english : sir ) आमदनी ठेके में काम है सर ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>Almost in a month - there is work according to...</td>\n","      <td>एक महीने में लगभग - लगभग ठेके के हिसाब का काम ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>AI_170_result_slice_70000</td>\n","      <td>my name is Sonu.</td>\n","      <td>मेरा नाम सोनू है।</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f07849be-b834-45b2-b07e-082ab97975c1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f07849be-b834-45b2-b07e-082ab97975c1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f07849be-b834-45b2-b07e-082ab97975c1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}],"source":["df = pd.read_csv('/content/drive/MyDrive/translated_final_merged_all.csv')\n","df.head()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":600,"status":"ok","timestamp":1675340860867,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"YoXVASGG8KUa","outputId":"f42b8623-2802-4a17-e4d4-363ce38e679e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   2  \\\n","0  I run the machine for the jeans etc., which ar...   \n","1  Apart from this, sir, after doing normal work ...   \n","2  Sir, income is work in contract, Sir what happ...   \n","3  Almost in a month - there is work according to...   \n","4                                   my name is Sonu.   \n","\n","                                          hindi_text  label  \n","0  जो जीन्स वगैरा बनती है ना जो इनकी लुपियाँ होती...    0.0  \n","1  इसके आलावा सर ( english : sir ) तो में नार्मल ...    0.0  \n","2  सर ( english : sir ) आमदनी ठेके में काम है सर ...    0.0  \n","3  एक महीने में लगभग - लगभग ठेके के हिसाब का काम ...    0.0  \n","4                                  मेरा नाम सोनू है।    0.0  "],"text/html":["\n","  <div id=\"df-5f9780fb-d53c-4909-b5a3-f8a0b380a786\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>hindi_text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I run the machine for the jeans etc., which ar...</td>\n","      <td>जो जीन्स वगैरा बनती है ना जो इनकी लुपियाँ होती...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Apart from this, sir, after doing normal work ...</td>\n","      <td>इसके आलावा सर ( english : sir ) तो में नार्मल ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sir, income is work in contract, Sir what happ...</td>\n","      <td>सर ( english : sir ) आमदनी ठेके में काम है सर ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Almost in a month - there is work according to...</td>\n","      <td>एक महीने में लगभग - लगभग ठेके के हिसाब का काम ...</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>my name is Sonu.</td>\n","      <td>मेरा नाम सोनू है।</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f9780fb-d53c-4909-b5a3-f8a0b380a786')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5f9780fb-d53c-4909-b5a3-f8a0b380a786 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5f9780fb-d53c-4909-b5a3-f8a0b380a786');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}],"source":["df.drop(\"1\", axis=1, inplace=True)\n","df.drop(\"0\", axis=1, inplace=True)\n","df.drop('Unnamed: 0', axis=1, inplace=True)\n","df.rename(columns = {'3':'hindi_text', '4' :'label'}, inplace = True)\n","df.head()"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1675340863389,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"8ZPkDjFt8PQh","outputId":"330beeea-41c5-43f1-b02b-26d1cd5fbf75"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5117, 3)"]},"metadata":{},"execution_count":18}],"source":["df = df[df['label'].notna()]\n","df.shape"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1675340866200,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"Ko1eUVZY8SCt","outputId":"dfe060cf-c11f-4e3d-afc1-dfb53babe01e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                      2  \\\n","0     I run the machine for the jeans etc., which ar...   \n","1     Apart from this, sir, after doing normal work ...   \n","2     Sir, income is work in contract, Sir what happ...   \n","3     Almost in a month - there is work according to...   \n","4                                      my name is Sonu.   \n","...                                                 ...   \n","5141  A month would have been a little too many 40 d...   \n","5142                          I make myself for myself.   \n","5143  And those people make their own family for the...   \n","5144  I was separated, it was separated, everything ...   \n","5145  No, she is the eldest, so the one who is her d...   \n","\n","                                             hindi_text  label  \n","0     जो जीन्स वगैरा बनती है ना जो इनकी लुपियाँ होती...      0  \n","1     इसके आलावा सर ( english : sir ) तो में नार्मल ...      0  \n","2     सर ( english : sir ) आमदनी ठेके में काम है सर ...      0  \n","3     एक महीने में लगभग - लगभग ठेके के हिसाब का काम ...      0  \n","4                                     मेरा नाम सोनू है।      0  \n","...                                                 ...    ...  \n","5141  एक महीने थोड़ा बहुत ज्यादा 40 दिन हो गये होंगे ...      2  \n","5142               मैं अपने लिए तो अपने आप बनाती हूँ |       0  \n","5143  और वो लोग अपने लिए अपने आप बनाते है उनकी फॅमिली |      0  \n","5144  में अलग हो गया था अलग हो गया था सब मतलब  1 साल...      2  \n","5145  नहीं वो  है बड़ी वाली तो जो उनकी बेटी है और जो ...      0  \n","\n","[5117 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-cd9f6877-4d0e-45b3-854e-aa773b6641cb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2</th>\n","      <th>hindi_text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I run the machine for the jeans etc., which ar...</td>\n","      <td>जो जीन्स वगैरा बनती है ना जो इनकी लुपियाँ होती...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Apart from this, sir, after doing normal work ...</td>\n","      <td>इसके आलावा सर ( english : sir ) तो में नार्मल ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sir, income is work in contract, Sir what happ...</td>\n","      <td>सर ( english : sir ) आमदनी ठेके में काम है सर ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Almost in a month - there is work according to...</td>\n","      <td>एक महीने में लगभग - लगभग ठेके के हिसाब का काम ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>my name is Sonu.</td>\n","      <td>मेरा नाम सोनू है।</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5141</th>\n","      <td>A month would have been a little too many 40 d...</td>\n","      <td>एक महीने थोड़ा बहुत ज्यादा 40 दिन हो गये होंगे ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>5142</th>\n","      <td>I make myself for myself.</td>\n","      <td>मैं अपने लिए तो अपने आप बनाती हूँ |</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5143</th>\n","      <td>And those people make their own family for the...</td>\n","      <td>और वो लोग अपने लिए अपने आप बनाते है उनकी फॅमिली |</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5144</th>\n","      <td>I was separated, it was separated, everything ...</td>\n","      <td>में अलग हो गया था अलग हो गया था सब मतलब  1 साल...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>5145</th>\n","      <td>No, she is the eldest, so the one who is her d...</td>\n","      <td>नहीं वो  है बड़ी वाली तो जो उनकी बेटी है और जो ...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5117 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd9f6877-4d0e-45b3-854e-aa773b6641cb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-cd9f6877-4d0e-45b3-854e-aa773b6641cb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-cd9f6877-4d0e-45b3-854e-aa773b6641cb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}],"source":["df[['label']] = df[['label']].astype(int)\n","df"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"zL87q5Gu8U36","executionInfo":{"status":"ok","timestamp":1675340868764,"user_tz":-330,"elapsed":6,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"}}},"outputs":[],"source":["# Creating sentence, label lists and adding Bert tokens\n","sentences = df.hindi_text.values\n","\n","# Adding CLS and SEP tokens at the beginning and end of each sentence for BERT\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","labels = df.label.values"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3889,"status":"ok","timestamp":1675340878172,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"Lt7ILnsm8bcU","outputId":"a4aac7bb-6a64-4a08-e86a-80eef42466cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenize the first sentence:\n","['[CLS]', 'जो', 'जीन्स', 'व', '##गै', '##रा', 'बनती', 'है', 'ना', 'जो', 'इनकी', 'ल', '##ुप', '##ियाँ', 'होती', 'है', 'उनकी', 'मशीन', 'चलता', 'हूँ', '।', '[SEP]']\n","22\n"]}],"source":["#@title Activating the BERT Tokenizer\n","tokenizer = BertTokenizer.from_pretrained(\"google/muril-base-cased\")\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","print (\"Tokenize the first sentence:\")\n","print(tokenized_texts[0])\n","print (len(tokenized_texts[0]))"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1675340881610,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"N6lASuoC8l2r","outputId":"2264006e-3f1f-4284-9270-c50c7a15b4fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["22\n","128\n"]}],"source":["#Processing the data\n","# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n","# In the original paper, the authors used a length of 512.\n","MAX_LEN = 128\n","\n","# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","print(len(input_ids[0]))\n","# Pad our input tokens\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","print(len(input_ids[0]))"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1675340883880,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"VgK1I06h8zRK","outputId":"4e624b1f-585c-4908-c1a0-ce6e2c6fe344"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n","4617\n","500\n","4617\n"]}],"source":["#Create attention masks\n","attention_masks = []\n","\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in input_ids:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)\n","\n","print(type(input_ids))\n","train_ids = input_ids[0:-500]\n","train_label = labels[0:-500]\n","test_ids = input_ids[-500:]\n","test_label = labels[-500:]\n","train_attention_masks = attention_masks[0:-500]\n","test_attention_masks = attention_masks[-500:]\n","print(len(train_label))\n","print(len(test_attention_masks))\n","print(len(train_ids))"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"rHAU1KD284SH","executionInfo":{"status":"ok","timestamp":1675340886228,"user_tz":-330,"elapsed":7,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"}}},"outputs":[],"source":["# Splitting data into train and validation sets\n","# Use train_test_split to split our data into train and validation sets for training\n","\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_ids, train_label,random_state = 2018, test_size = 0.1 )\n","train_masks, validation_masks, _, _ = train_test_split(train_attention_masks, train_ids,\n","                                             random_state=2018, test_size=0.1)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1675340888968,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"Z2FzK9Ay8692","outputId":"8831fab0-796e-4112-a3df-1c54083716e0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":25}],"source":["type(validation_masks)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1675340891121,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"zWJII1GL89po","outputId":"c3ce22f9-738e-47a9-e0e0-ab24a88f2147"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch.Tensor'>\n"]}],"source":["#Converting all the data into torch tensors\n","# Torch tensors are the required datatype for our model\n","\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)\n","print(type(train_inputs))"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1675340893976,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"wnfT1j5X9AxA","outputId":"c2a2cba9-8f91-4b5a-d445-68892c28268e"},"outputs":[{"output_type":"stream","name":"stdout","text":["4155\n"]}],"source":["# Selecting a Batch Size and Creating and Iterator\n","# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n","batch_size = 16\n","\n","# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n","# with an iterator the entire dataset does not need to be loaded into memory\n","print(len(train_inputs))\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1675340896116,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"rjUNiCdq-7dW","outputId":"8e78a6a9-a2b1-4599-b8aa-cd5fc20e794e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":28}],"source":["isinstance(model, nn.DataParallel)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1675340900274,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"},"user_tz":-330},"id":"81s7TNFE9FjM","outputId":"ebebfee9-25aa-46b2-f0ce-9fc170245c36"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataParallel(\n","  (module): BertForSequenceClassification(\n","    (bert): BertModel(\n","      (embeddings): BertEmbeddings(\n","        (word_embeddings): Embedding(197285, 768, padding_idx=0)\n","        (position_embeddings): Embedding(512, 768)\n","        (token_type_embeddings): Embedding(2, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): BertEncoder(\n","        (layer): ModuleList(\n","          (0): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (1): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (2): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (3): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (4): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (5): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (6): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (7): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (8): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (9): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (10): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (11): BertLayer(\n","            (attention): BertAttention(\n","              (self): BertSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): BertSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): BertIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): BertOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","      (pooler): BertPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=768, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":29}],"source":["model"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"OVTFn28q9LHF","executionInfo":{"status":"ok","timestamp":1675340903194,"user_tz":-330,"elapsed":7,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"}}},"outputs":[],"source":["# Optimizer Grouped Parameters\n","# reference:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L102\n","\n","# Don't apply weight decay to any parameters whose names include these tokens.\n","# (Here, the BERT doesn't have `gamma` or `beta` parameters, only `bias` terms)\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'LayerNorm.weight']\n","# Separate the `weight` parameters from the `bias` parameters. \n","# - For the `weight` parameters, this specifies a 'weight_decay_rate' of 0.01. \n","# - For the `bias` parameters, the 'weight_decay_rate' is 0.0. \n","optimizer_grouped_parameters = [\n","    # Filter for all parameters which *don't* include 'bias', 'gamma', 'beta'.\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.1},\n","    \n","    # Filter for parameters which *do* include those.\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","# Note - `optimizer_grouped_parameters` only includes the parameter values, not \n","# the names."]},{"cell_type":"code","execution_count":31,"metadata":{"id":"uKuA2vunAcEk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675340905528,"user_tz":-330,"elapsed":10,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"}},"outputId":"ef540bcd-dccb-49b6-ac76-608088ff6231"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# The Hyperparameters for the Training Loop \n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 3\n","\n","optimizer = AdamW(optimizer_grouped_parameters,\n","                  lr = 3e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                  )\n","# Total number of training steps is number of batches * number of epochs.\n","# `train_dataloader` contains batched data so `len(train_dataloader)` gives \n","# us the number of batches.\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0.1, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"r83nnrdpAf-n","executionInfo":{"status":"ok","timestamp":1675340907561,"user_tz":-330,"elapsed":8,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"}}},"outputs":[],"source":["#Creating the Accuracy Measurement Function\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"khjjPdj_AkBI","outputId":"47727aaf-3641-4f38-9745-64f29b4f86fb","executionInfo":{"status":"ok","timestamp":1675341223898,"user_tz":-330,"elapsed":313618,"user":{"displayName":"Chaitali Shah","userId":"09292214519824111146"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\rEpoch:   0%|          | 0/3 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Train loss: 1.2576605021953582\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  33%|███▎      | 1/3 [01:46<03:32, 106.13s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.4390394088669951\n","Train loss: 0.9829754274625044\n"]},{"output_type":"stream","name":"stderr","text":["\rEpoch:  67%|██████▋   | 2/3 [03:30<01:44, 104.82s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.5769704433497537\n","Train loss: 0.8390104850897422\n"]},{"output_type":"stream","name":"stderr","text":["Epoch: 100%|██████████| 3/3 [05:13<00:00, 104.63s/it]"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.6117610837438423\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# The Training Loop\n","t = [] \n","\n","# Store our loss and accuracy for plotting\n","train_loss_set = []\n","\n","# trange is a tqdm wrapper around the normal python range\n","for _ in trange(epochs, desc=\"Epoch\"):\n","  \n","  \n","  # Training\n","  \n","  # Set our model to training mode (as opposed to evaluation mode)\n","  model.train()\n","  \n","  # Tracking variables\n","  tr_loss = 0\n","  nb_tr_examples, nb_tr_steps = 0, 0\n","  \n","  # Train the data for one epoch\n","  for step, batch in enumerate(train_dataloader):\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    # Clear out the gradients (by default they accumulate)\n","    optimizer.zero_grad()\n","    # Forward pass\n","    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","    loss = outputs['loss']\n","    train_loss_set.append(loss.item())    \n","    # Backward pass\n","    loss.backward()\n","    # Update parameters and take a step using the computed gradient\n","    optimizer.step()\n","\n","    # Update the learning rate.\n","    scheduler.step()\n","    \n","    \n","    # Update tracking variables\n","    tr_loss += loss.item()\n","    nb_tr_examples += b_input_ids.size(0)\n","    nb_tr_steps += 1\n","\n","  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n","    \n","    \n","  # Validation\n","\n","  # Put model in evaluation mode to evaluate loss on the validation set\n","  model.eval()\n","\n","  # Tracking variables \n","  eval_loss, eval_accuracy = 0, 0\n","  nb_eval_steps, nb_eval_examples = 0, 0\n","\n","  # Evaluate data for one epoch\n","  for batch in validation_dataloader:\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","    with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    \n","    # Move logits and labels to CPU\n","    logits = logits['logits'].detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    \n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f_2LEhGkAo__"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyNfefbFIgiEnzqpVbSAKyis"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"14cd2cddf5a34cd4804dfeee0fcd038c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e5f4a6494e3410b9e37e034d9f7ef11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe0f8b5bc57f475fb2476975ec50904e","placeholder":"​","style":"IPY_MODEL_6b713841b07a4b0a8a3021bda0a325f7","value":" 953M/953M [00:04&lt;00:00, 257MB/s]"}},"6170f638a1ab458cb23e540a8a003995":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b713841b07a4b0a8a3021bda0a325f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7181fe376c3f41b6a2366a31d2a6dcb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_96dca1e278734dbf9c2889b8d0dd6cc2","IPY_MODEL_9b72d04191bd44ab9f64c8eb7819a581","IPY_MODEL_3e5f4a6494e3410b9e37e034d9f7ef11"],"layout":"IPY_MODEL_6170f638a1ab458cb23e540a8a003995"}},"96dca1e278734dbf9c2889b8d0dd6cc2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bea265908ebe45b4b88806ecad1f722f","placeholder":"​","style":"IPY_MODEL_b6757b87f2524f91ad554c76e0668d4e","value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"}},"9b72d04191bd44ab9f64c8eb7819a581":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cecc940a23794fa8b233dbf101786758","max":953477430,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14cd2cddf5a34cd4804dfeee0fcd038c","value":953477430}},"b6757b87f2524f91ad554c76e0668d4e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bea265908ebe45b4b88806ecad1f722f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cecc940a23794fa8b233dbf101786758":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe0f8b5bc57f475fb2476975ec50904e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9588b5813ef5456aa57b7924fcea30a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b40a084bacfd4958920ae9976d450481","IPY_MODEL_1afd48a2ae2741eca677e09b7e594849","IPY_MODEL_700c5f4355444766aaa229cf60bd1244"],"layout":"IPY_MODEL_71215226a4414985bc165bad46ff32ed"}},"b40a084bacfd4958920ae9976d450481":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6910125828ea451ea922f7be1f6c0577","placeholder":"​","style":"IPY_MODEL_7f8650108e1e468da2fa5cd26243f07a","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"1afd48a2ae2741eca677e09b7e594849":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ca800bb00e548eaaf553a8732f40936","max":3162999,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6256935e983a42d28787c18ecd22f6f0","value":3162999}},"700c5f4355444766aaa229cf60bd1244":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f02327d3b21b4a68b3d920fabb2a3bee","placeholder":"​","style":"IPY_MODEL_9a549e69425740ea9f1c74819a400835","value":" 3.16M/3.16M [00:01&lt;00:00, 2.02MB/s]"}},"71215226a4414985bc165bad46ff32ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6910125828ea451ea922f7be1f6c0577":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f8650108e1e468da2fa5cd26243f07a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ca800bb00e548eaaf553a8732f40936":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6256935e983a42d28787c18ecd22f6f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f02327d3b21b4a68b3d920fabb2a3bee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a549e69425740ea9f1c74819a400835":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cf6c7d8a6604f599acd9d82c3f7e61e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c8c4c8cbf9647d0b25033186427337b","IPY_MODEL_35f8e944ab0447778cb8e66c7df37929","IPY_MODEL_97d3818d2f6d4342971747d8e8516c55"],"layout":"IPY_MODEL_743d5826bda94e9bb3e95907720cff9c"}},"3c8c4c8cbf9647d0b25033186427337b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28a02a41b1e5464aa685137c787f4c6d","placeholder":"​","style":"IPY_MODEL_e908c8dbe4604eb097c5530c4dba012d","value":"Downloading (…)cial_tokens_map.json: 100%"}},"35f8e944ab0447778cb8e66c7df37929":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d4863c9e7ab479c9f8137690d8cd9b6","max":113,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6803d68c549d419682023aadbd8e8ff5","value":113}},"97d3818d2f6d4342971747d8e8516c55":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2f62f1da60d44309820e6082ceb9afc","placeholder":"​","style":"IPY_MODEL_3fd7b2cb65b3450783dadf406c3780b4","value":" 113/113 [00:00&lt;00:00, 4.51kB/s]"}},"743d5826bda94e9bb3e95907720cff9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28a02a41b1e5464aa685137c787f4c6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e908c8dbe4604eb097c5530c4dba012d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d4863c9e7ab479c9f8137690d8cd9b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6803d68c549d419682023aadbd8e8ff5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c2f62f1da60d44309820e6082ceb9afc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3fd7b2cb65b3450783dadf406c3780b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"272849c61db64f9f936662115753b3ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_34cbe33922334c0db3f1852c8a6c689d","IPY_MODEL_8e0facfc3e5a44f68ab10f75aa230895","IPY_MODEL_a58b1bfbc6364adebec0adb04c03b68c"],"layout":"IPY_MODEL_ec6c57c84dba448a94b78eced1b39428"}},"34cbe33922334c0db3f1852c8a6c689d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef3aebf344a7477a921069370c631ee0","placeholder":"​","style":"IPY_MODEL_47f5bb58546c4ff7b1e7e60350ce99e4","value":"Downloading (…)okenizer_config.json: 100%"}},"8e0facfc3e5a44f68ab10f75aa230895":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3f35d9d72fd40abb6d7d9b1edcf249f","max":206,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0035e4f59574996be1cab12acf72325","value":206}},"a58b1bfbc6364adebec0adb04c03b68c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56de27321ef14c4e98873bf2d1fa9869","placeholder":"​","style":"IPY_MODEL_21959b3bf2064377aca7bfe52029a35b","value":" 206/206 [00:00&lt;00:00, 10.3kB/s]"}},"ec6c57c84dba448a94b78eced1b39428":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef3aebf344a7477a921069370c631ee0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47f5bb58546c4ff7b1e7e60350ce99e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3f35d9d72fd40abb6d7d9b1edcf249f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0035e4f59574996be1cab12acf72325":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56de27321ef14c4e98873bf2d1fa9869":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21959b3bf2064377aca7bfe52029a35b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"889fbcb3cffb4daba84cf1e3c24f157a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_60bb048ca3da42e6bd58b2a7d83a710f","IPY_MODEL_39a51dbbfa034d68bf593eb604407a7f","IPY_MODEL_cb714e75828e4d5abd2c095affd44017"],"layout":"IPY_MODEL_4a0348b253a14c98a4631c1fa3ab7b14"}},"60bb048ca3da42e6bd58b2a7d83a710f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1189a1b790842229a9f5f4b0c232c58","placeholder":"​","style":"IPY_MODEL_f50d2fd6f14146a6be4f97203ba86e5f","value":"Downloading (…)lve/main/config.json: 100%"}},"39a51dbbfa034d68bf593eb604407a7f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_676b3b277c064d95821f59484f858724","max":411,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5a8585ba9b8040b489e67a6c484b504e","value":411}},"cb714e75828e4d5abd2c095affd44017":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b6ce6c2e08f499c996b7cfd618d33d9","placeholder":"​","style":"IPY_MODEL_8309d4c04c394fb9a6278066767ed182","value":" 411/411 [00:00&lt;00:00, 21.3kB/s]"}},"4a0348b253a14c98a4631c1fa3ab7b14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1189a1b790842229a9f5f4b0c232c58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f50d2fd6f14146a6be4f97203ba86e5f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"676b3b277c064d95821f59484f858724":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a8585ba9b8040b489e67a6c484b504e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b6ce6c2e08f499c996b7cfd618d33d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8309d4c04c394fb9a6278066767ed182":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}